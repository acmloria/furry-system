{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "import time\n",
    "\n",
    "time_per_file = []\n",
    "\n",
    "# all_data = [] #a list that will contain all data (index per applicant basis)\n",
    "\n",
    "# path and file_name\n",
    "def read_file(path_file):\n",
    "#     wb = load_workbook(path_file, read_only=True)   # open an Excel file and return a workbook\n",
    "\n",
    "#     if 'Applications' in wb.sheetnames:\n",
    "    dataframe = pd.read_excel(path_file)\n",
    "    return dataframe\n",
    "#     else:\n",
    "#         dataframe = pd.read_excel(path_file, sheet_name=\"Application Template\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "#Drop unnecessary columns\n",
    "def drop_columns(df):\n",
    "\n",
    "    drop_column_names = []\n",
    "    \n",
    "    for col in dataframe.columns:\n",
    "        if re.search(\"^Unnamed\", col, re.IGNORECASE) is None:\n",
    "            drop_column_names.append(col)\n",
    "    \n",
    "    df = df.drop(drop_column_names, axis=1)\n",
    "\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        col = col.replace(\".\",\"_\")\n",
    "        col = col.replace(\": \",\"_\")\n",
    "        new_columns.append(col.lower())\n",
    "    \n",
    "    df.columns = new_columns    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_related_columns(df):\n",
    "    df[\"row_number\"] = df.index # assigning rows for individual's grouping of data later\n",
    "    df[\"unnamed_1\"] = df[\"unnamed_1\"].replace(\" \",\"_\",regex=True).str.lower() #converting this to variable-like\n",
    "    df[\"unnamed_2\"] = df[\"unnamed_2\"].apply(lambda x: x if x!=\"None\" and x!=\"#N/A\" and x!=\"NaN\" else None).astype(str)\n",
    "\n",
    "    df[\"unnamed_4\"] = df[\"unnamed_4\"].replace(\" \",\"_\",regex=True).str.lower()\n",
    "    df[\"unnamed_5\"] = df[\"unnamed_5\"].apply(lambda x: x if x!=\"None\" and x!=\"#N/A\" and x!=\"NaN\"else None).astype(str)\n",
    "\n",
    "    df[\"unnamed_6\"] = df[\"unnamed_6\"].replace(\" \",\"_\",regex=True).str.lower()\n",
    "    df[\"unnamed_7\"] = df[\"unnamed_7\"].apply(lambda x: x if x!=\"None\" and x!=\"#N/A\" and x!=\"NaN\"else None).astype(str)\n",
    "\n",
    "    df[\"unnamed_9\"] = df[\"unnamed_9\"].replace(\" \",\"_\",regex=True).str.lower()\n",
    "    df[\"unnamed_10\"] = df[\"unnamed_10\"].apply(lambda x: x if x!=\"None\" and x!=\"#N/A\" and x!=\"NaN\"else None).astype(str) \n",
    "\n",
    "    df[\"unnamed_20\"] = df[\"unnamed_20\"].replace(\" \",\"_\",regex=True).str.lower()\n",
    "    df[\"unnamed_21\"] = df[\"unnamed_21\"].apply(lambda x: x if x!=\"None\" and x!=\"#N/A\" and x!=\"NaN\"else None).astype(str)\n",
    "\n",
    "    #combining related data - by category and value\n",
    "    df[\"Notice_Credit_Decision\"] = df[\"unnamed_1\"].astype(str) +\" | \" +df[\"unnamed_2\"].astype(str)\n",
    "    df[\"Basic_Info\"] = df[\"unnamed_4\"].astype(str) +\" | \" +df[\"unnamed_5\"].astype(str)\n",
    "    df[\"MC_Details\"] = df[\"unnamed_6\"].astype(str) +\" | \" +df[\"unnamed_7\"].astype(str)\n",
    "    df[\"Credit_Info\"] = df[\"unnamed_9\"].astype(str) +\" | \" +df[\"unnamed_10\"].astype(str)\n",
    "    df[\"DTIR\"] = df[\"unnamed_20\"].astype(str) +\" | \" +df[\"unnamed_21\"].astype(str)\n",
    "    \n",
    "#     for col in df.columns:\n",
    "#         df[col] = df[col].astype(str)\n",
    "#         df[col] = df[col].str.replace(\",\",\"\")\n",
    "    \n",
    "    groupings_list = [df[\"Notice_Credit_Decision\"].to_dict(), df[\"Basic_Info\"].to_dict(), df[\"MC_Details\"].to_dict(), df[\"Credit_Info\"].to_dict(), df[\"DTIR\"].to_dict()]\n",
    "\n",
    "# all_data = []\n",
    "    return groupings_list\n",
    "\n",
    "\n",
    "def group_dataset(x):\n",
    "# def group_dataset(x, dataset, dataset_list):\n",
    "#     x is a multiple of 26\n",
    "    y = x/26\n",
    "    \n",
    "    applicant_data_set = []\n",
    "    for group in grouping:\n",
    "        applicant_data={}\n",
    "        applicant_set_per_group = {k:v for k,v in group.items() if k>=x and k<26*(y+1)}\n",
    "        applicant_data[x] = {v for v in applicant_set_per_group.values()}\n",
    "        \n",
    "        applicant_data_set.append(applicant_data)\n",
    "\n",
    "    for row_number in applicant_data_set[0].keys():\n",
    "        combined_data_tuple = []\n",
    "        for d in applicant_data_set:\n",
    "            combined_data_tuple.append(d[row_number])\n",
    "    \n",
    "    #manipulate combined_data_tuplee\n",
    "    t = []\n",
    "    for s in combined_data_tuple:\n",
    "        s = list(s)\n",
    "        for r in s:\n",
    "            t.append(r)\n",
    "            \n",
    "    all_data.append(t)\n",
    "\n",
    "def get_first_occurence(dataset):\n",
    "    for key, value in dataset[0].items():\n",
    "        if key%26 == 0:\n",
    "            group_dataset(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Sample/2018/April\n",
      "../Sample/2018/August\n",
      "../Sample/2018/August/Application August  2018 beyond chelle.xlsx\n",
      "../Result/2018/August/Cleaned_application_august__2018_beyond_chelle.xlsx\n",
      "../Sample/2018/August/APPLICATION TEMPLATE 2018 AUGUTS MANUEL.xlsx\n",
      "../Result/2018/August/Cleaned_application_template_2018_auguts_manuel.xlsx\n",
      "../Sample/2018/August/Application template August 2018 fnb.xlsx\n",
      "../Result/2018/August/Cleaned_application_template_august_2018_fnb.xlsx\n",
      "../Sample/2018/August/Application Templates 2018 (August).xlsx\n",
      "../Result/2018/August/Cleaned_application_templates_2018_(august).xlsx\n",
      "../Sample/2018/August/August  2018 mhelai.xlsx\n",
      "../Result/2018/August/Cleaned_august__2018_mhelai.xlsx\n",
      "../Sample/2018/August/lloyd Application August  2018.xlsx\n",
      "../Result/2018/August/Cleaned_lloyd_application_august__2018.xlsx\n",
      "../Sample/2018/December\n",
      "../Sample/2018/February\n",
      "../Sample/2018/January\n",
      "../Sample/2018/July\n",
      "../Sample/2018/June\n",
      "../Sample/2018/March\n",
      "../Sample/2018/May\n",
      "../Sample/2018/November\n",
      "../Sample/2018/October\n",
      "../Sample/2018/September\n"
     ]
    }
   ],
   "source": [
    "# for x in all_data_list\n",
    "def generate_columns(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"row_number\"] = df.index \n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col!=\"row_number\":\n",
    "            feature_columns  = [ \"{col}_category\".format(col=col), \"{col}_data\".format(col=col) ]\n",
    "            splitted_data = df[col].str.split(\" | \", n = 2, expand = True) \n",
    "            df[feature_columns[0]]= splitted_data[0]\n",
    "            df[feature_columns[1]]= splitted_data[2]\n",
    "            df[\"category\"] = splitted_data[0]\n",
    "            df[\"data\"] = splitted_data[2]\n",
    "\n",
    "            if col == 0:\n",
    "                df_category_data = df[[\"row_number\",\"0_category\" ,\"0_data\"]]\n",
    "                df_category_data.columns = [\"row_number\", \"category\", \"data\"]\n",
    "            else:\n",
    "                df_category_data = pd.concat([df_category_data[[\"row_number\",\"category\", \"data\"]], df[[\"row_number\",\"category\", \"data\"]]])\n",
    "\n",
    "            df = df.drop(col, axis=1)\n",
    "\n",
    "    df_category_data = df_category_data.mask(df_category_data[\"category\"].eq('None'))\n",
    "    df_category_data = df_category_data.mask(df_category_data[\"category\"].eq('nan'))\n",
    "    df_category_data = df_category_data.mask(df_category_data[\"category\"].eq(' '))\n",
    "    df_category_data = df_category_data.mask(df_category_data[\"category\"].eq('_'))\n",
    "    \n",
    "    df_category_data = df_category_data.mask(df_category_data[\"data\"].eq('None'))\n",
    "    df_category_data = df_category_data.mask(df_category_data[\"data\"].eq('nan'))\n",
    "    df_category_data = df_category_data.mask(df_category_data[\"data\"].eq(' '))\n",
    "    df_category_data = df_category_data.mask(df_category_data[\"data\"].eq('_'))\n",
    "\n",
    "    df_category_data.drop_duplicates(subset=[\"row_number\",\"category\"], keep=\"first\", inplace=True)\n",
    "    df_category_data.reset_index().set_index(['row_number'])\n",
    "\n",
    "    #this is where we generate columns for our excel file\n",
    "    df_generated_columns = df_category_data.pivot(index=\"row_number\", columns=[\"category\"], values=\"data\")\n",
    "\n",
    "    df_generated_columns = df_generated_columns.dropna(how=\"all\", axis=0)\n",
    "    df_generated_columns = df_generated_columns.dropna(how=\"all\", axis=1)\n",
    "\n",
    "    return df_generated_columns\n",
    "\n",
    "def generate_file(path, yy, mm, file_name, df):\n",
    "    #positioning important fields\n",
    "    df = df.dropna(subset=[\"customer_name\"], axis=0)\n",
    "    customer_name = df.pop(\"customer_name\")\n",
    "    age = df.pop(\"age\")\n",
    "    gross_income =df.pop(\"gross_income\")\n",
    "    dtir = df.pop(\"dtir\")\n",
    "    df.insert(0, \"customer_name\", customer_name)\n",
    "    df.insert(1, \"age\", age)\n",
    "    df.insert(2, \"gross_income\", gross_income)\n",
    "    df.insert(3, \"dtir\", dtir)\n",
    "    file_name = file_name.replace(\" \",\"_\").lower()\n",
    "    complete_file_name = \"{}{}/{}/Cleaned_{}\".format(path,yy,mm,file_name)\n",
    "    print(complete_file_name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    if not os.path.exists(\"{}{}\".format(path,yy)):\n",
    "        os.makedirs(\"{}{}\".format(path,yy))\n",
    "    if not os.path.exists(\"{}{}/{}/\".format(path,yy,mm)):\n",
    "        os.makedirs(\"{}{}/{}/\".format(path,yy,mm))\n",
    "        \n",
    "    if not os.path.isfile(complete_file_name):\n",
    "        df.to_excel(complete_file_name)\n",
    "    \n",
    "\n",
    "if __name__=='__main__':\n",
    "    path = '../Sample/'\n",
    "    path_result = '../Result/'\n",
    "    years = os.listdir(path)\n",
    "    for year in years:\n",
    "        year_path = \"{}{}/\".format(path,year)\n",
    "        months = os.listdir(year_path)\n",
    "        if year == \"2018\":\n",
    "            for month in months:\n",
    "                \n",
    "                month_path = \"{}{}\".format(year_path, month)\n",
    "                print(month_path)\n",
    "                files = os.listdir(month_path)\n",
    "                if month==\"August\":\n",
    "                    for file in files:\n",
    "                        \n",
    "                        file_path = \"{}/{}\".format(month_path, file)\n",
    "                        print(file_path)\n",
    "                        if os.path.isfile(file_path):\n",
    "                            start_time = time.time()\n",
    "                            dataframe = read_file(file_path)\n",
    "                            dataframe = drop_columns(dataframe)\n",
    "                            grouping = match_related_columns(dataframe) #returns a list of dictionaries [{}, {}, {}]\n",
    "                            all_data = []\n",
    "                            get_first_occurence(grouping)\n",
    "                            tabular_data = generate_columns(all_data)\n",
    "                            generate_file(path_result, year, month, file, tabular_data)\n",
    "                            end_time = time.time() - start_time\n",
    "                        \n",
    "                            time_per_file.append(time.strftime(\"%H:%M:%S\",time.gmtime(end_time)))\n",
    "                            f = open(\"time_2018_august.txt\", \"w\")\n",
    "                            f.write(', '.join(map(str, time_per_file)))\n",
    "                            f.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "                        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
